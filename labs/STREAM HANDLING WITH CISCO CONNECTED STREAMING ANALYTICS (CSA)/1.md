# <center>STREAM HANDLING WITH CISCO CONNECTED STREAMING ANALYTICS (CSA)</center>

Stream Processing Platform Used : Apache Kafka

Programming Language Used : Java, XML

Executed on : Hadoop Big Data Platform

Visualization tool Used : Canvas logview

## OVERVIEW

This learning lab can be used as a guide to get a high level understanding for using CSA(Connected Streaming Analytics) in  DLP(DevNet Data Learning Platform) platform. DLP platform has Kafka messaging framework that works from the backend. 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA11.jpeg?raw=true)

## PRE-REQUISITES

1.	Install Chrome Browser.

2.	Obtain access to the Data Learning Platform by creating an account at https://devnetsandbox.cisco.com/RM/Diagram/Index/d8b9476d-cb6f-4b44-a236-b8ebdb3d3ef9?diagramType=Topology (Detailed instructions given below)

3.	Basic understanding of Apache Hadoop and Big Data.

3.	Basic knowledge of Java, SQL and XML.


## LEARNING OBJECTIVES

1. To get familiarized with the DLP (Data Learning Platform)

2. To get a high level understanding of CSA.

3. To get a high level understanding of Apache Kafka.

4. To get familiarized with the ways to visualize the data using Canvas logview.

## TERMINOLOGIES USED

## Cisco® CONNECTED STREAMING ANALYTICS(CSA) - AN INTRODUCTION

Cisco® Connected Streaming Analytics (CSA) is an analytics platform that delivers predictive, actionable insights from high-velocity streams of live data.

<b>Key Features</b>

1. Streaming query processing supports active, continuous monitoring of live data. This provides instantaneous, real-time analysis and action, as well as efficient use of computing resources. 

2. CSA’s framework and interfaces are ideal for use case development across a wide variety of business and network management functions and industries. 

3. CSA provides real-time insights into big data views to support actionable events and dynamic dashboards to help you get more value out of your data.

For more details, please refer:

http://www.cisco.com/c/dam/en/us/products/collateral/analytics-automation-software/streaming-analytics/connected-streaming-analytics-aag.pdf

http://www.cisco.com/c/dam/en/us/products/collateral/analytics-automation-software/streaming-analytics/connected-streaming-analytics.pdf

## APACHE KAFKA? - AN INTRODUCTION

Kafka is a distributed streaming platform that is designed to be fast, scalable, and durable. It has 3 key capabilities:

1.	It lets you publish and subscribe to streams of records. In this respect it is similar to a message queue or enterprise messaging system.
2.	It lets you store streams of records in a fault-tolerant way.
3.	It lets you process streams of records as they occur.

It gets used for two broad classes of application:

1.	Building real-time streaming data pipelines that reliably get data between systems or applications
2.	Building real-time streaming applications that transform or react to the streams of data

For more details, please refer:
https://kafka.apache.org/


### HADOOP - AN INTRODUCTION ###

Apache Hadoop is an open-source software framework for distributed storage and distributed processing of very large data sets on computer clusters built from commodity hardware. To understand Hadoop, there are two fundamental things about it -  How Hadoop stores files and how it processes data.The framework that is used in hadoop to process data is called MapReduce.

All the modules in Hadoop are designed with a fundamental assumption that hardware failures are common and should be automatically handled by the framework. The core of Apache Hadoop consists of a storage part, known as Hadoop Distributed File System (HDFS), and a processing part called MapReduce. Hadoop splits files into large blocks and distributes them across nodes in a cluster.

Example : Imagine a file that is larger than the capacity of a computer then it would not be possible to store that file. Hadoop allows to store files bigger than what can be stored on one particular node or server. So it provides an ability to store very, very large files and also lets to store many, many files.

For more details, please refer:
(https://en.wikipedia.org/wiki/Apache_Hadoop)


### DLP - AN INTRODUCTION ###

The DevNet Data Learning Platform (DLP) is a Big-Data learning platform connected with an easy to learn UI to help you break into the world of Big-Data development.  Backed with Docker, best-in-class open source Big-Data tools and Cisco API’s, Big-Data Scientists and Developers can leverage DLP to easily build solutions, visualize data and turn POC’s for production applications. The DLP environment comes with an inbuilt cloud based IDE (Integrated Development Environment) built on Hadoop.

For more details, please refer:
https://developer.cisco.com/site/dlp/docs/overview/


## PROCESS OVERVIEW 

In this lab, we will use a Log Simulator, CSA Engine and the customised handler.
</br>

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Process6.jpeg?raw=true)

Please follow the steps given below to launch the workspace and execute the program.

### <b>Step 1 : Login to DLP</b>

Access the link - https://developer.cisco.com/site/dlp/ and click on button Request Access. Please refer the screen shown below:</br>. 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess1.jpeg?raw=true)

On click of Request access, you will be navigated to the following page:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess2.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess2.jpeg" width="400" height="300" />

<b>Existing User?</b>

Click on DevNet logo and provide the credentials in the login page. Please refer the screen below:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess7.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess7.jpeg" width="400" height="300" />

On click of DevNet Logo:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess3.jpeg?raw=true)

<b>New User?</b>

Click on “Register Account” button and create a new login profile. Please refer the screen below:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess8.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess8.jpeg" width="400" height="300" />

On click of "Register Account":

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess5.jpeg?raw=true)


<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess6.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess6.jpeg" width="300" height="400" />

On successful registration, navigate to DLP login page and login with the credentials created:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess3.jpeg?raw=true)

### <b>Step 2 : DLP Dashboard Page</b>

On login, you will be directed to the DevNet DLP (Data Learning Platform)dashboard page as shown in the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/DevNetLanding.jpeg?raw=true)

### <b>Step 3 : Select Learning Lab and Start</b>

From Learning Labs pane, select the learning lab "Stream handling with Cisco Connected Streaming Analytics(CSA)" and click on "Start" button as shown in screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA2.jpeg?raw=true)

### <b>Step 4 : Workspace Page</b>

On click of Start button, user will be navigated to a workspace page where all the components - IDE, Tools and Microservices required to execute the program are available. Please refer the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA1.jpeg?raw=true)

### <b>Step 5 : Tasks in Workspace</b>

Points to Note:
The order for starting the services is as shown below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA.jpeg?raw=true)

* Start all the tasks except logview in the specific sequence as mentioned in the flow diagram above. 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA4.jpeg?raw=true)

* If any of the tasks other than logview is in stopped status then click on it to start again. Please refer screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA3.jpeg?raw=true)

* Click launch on cloud IDE service (where eclipse icon is shown) and user will be navigated to a pre-configured IDE (Integrated Development Environment) as shown in the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA5.jpeg?raw=true)

### <b>Step 6 : Stop, Build and Run the Program</b>

Select "Stop" from the IDE combo box to stop the handler. Please refer the screenshot below:

![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/step13.jpg?raw=true)

On successful completion of build command, the screen will look as shown below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA6.jpeg?raw=true)

Select "Build" from the IDE combo box to build the handler. Please refer the screenshot below:

![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/step14.jpg?raw=true)

On successful completion of build command, the screen will look as shown below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA7.jpeg?raw=true)

Select "Run" from the IDE combo box to start the handler. Please refer the screenshot below:

![Figure](https://raw.githubusercontent.com/prakdutt/data-dev-learning-labs/master/labs/develop-stream-handler-cisco-csa/assets/images/step15.jpg)

On successful completion of run command, the screen will look as shown below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA8.jpeg?raw=true)

### <b>Step 7 : Start Logview service from DLP</b>

* Start the logview service. Please refer screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA10.jpeg?raw=true)

* Launch logview and visualize the output. 

logview will open in a seperate tab and the output would be as shown below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/STREAM%20HANDLING%20WITH%20CISCO%20CONNECTED%20STREAMING%20ANALYTICS%20(CSA)/assets/images/CSA9.jpeg?raw=true)

P.S: This is a web Server live streaming Log visualisation.The Red line depicts Http 404 hit and the blue line depicts Http 200.You can view the number of web server hits in a specific time frame and evaluate the success and failures(Http 404 represents failure and Http 200 represents success).

## LESSONS LEARNT

1. High level understanding of CSA.

2. High level understanding of Apache Kafka.

3. How to visualize the data using Canvas logview.


# <center>Congratulations! You have successfully completed the Learning Lab!
