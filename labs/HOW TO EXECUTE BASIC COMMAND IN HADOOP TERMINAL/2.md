
### HOW TO USE APACHE SPARK-SHELL TO INTERACT WITH SPARK CLUSTER###

###### Step 1:
From Hadoop Terminal, use echo command to find the path as shown below:
```jason
echo $HDFS
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic29.png?raw=true)

Note: The path obtained needs to be used in commands shown below to replace {$HDFS}.


###### Step 2:
Spark shell interactive environment needs to be launched from terminal.Please follow the steps given below. User could launch the Spark shell interactive environment either in local mode or in cluster mode but not in both of them.

To launch in Local Mode, please follow the command given below:

```jason
spark-shell
```

To launch in cluster Mode, please follow the command given below:

```jason
spark-shell --master yarn --deploy-mode client
```

###### Step 4:

Execute word count transformation program with basic spark code as follows. The commands mentioned below needs to be executed in sequential order.

```jason
val inputfile = sc.textFile("${HDFS}hadoop-learning-labs-people.txt") 
```
Replace the hdfs path with the path obtained with Echo command in Step 1.

Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic25.png?raw=true)

```jason
val counts = inputfile.flatMap(line => line.split(" ")).map(word => (word, 1)).reduceByKey(_+_);
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic26.png?raw=true)
```jason
counts.cache()
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic27.png?raw=true)
```jason
counts.toArray().foreach(println)
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic28.png?raw=true)


Steps Performed:

1. Load input data from a file.
2. Read an input set of text and split the data in to words.
3. Counts the number of times each word appears and transform it in to word and count.
4. Save the word count output back to a text file.
5. Print the output to terminal.


###### Step 5:

<b>Using SQL to do analytics in Spark shell</b>

There are two different ways:

1. Using Spark SQL
2. Using Normal SQL

The commands mentioned below needs to be executed in sequential order. 

<b>Using Spark SQL</b>

```jason
val sqlContext = new org.apache.spark.sql.SQLContext(sc)
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic30.png?raw=true)


```jason
val df = sqlContext.jsonFile("${HDFS}hadoop-learning-labs-people.json ")
```
Replace the hdfs path with the path obtained with Echo command in Step 1.

Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic31.png?raw=true)

```jason
df.show()
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic32.png?raw=true)

```jason
df.select("name").show()
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic33.png?raw=true)

```jason
df.select(df("name"), df("age") + 1).show()
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic34.png?raw=true)

```jason
df.filter(df("age") > 21).show()
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic35.png?raw=true)

```jason
df.groupBy("age").count().show()
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic36.png?raw=true)

<b>Using Normal SQL</b>

```jason
import sqlContext.implicits._
```

Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic37.png?raw=true)

```jason
case class Person(name: String, age: Int)
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic38.png?raw=true)

```jason
val people = sc.textFile("${HDFS}hadoop-learning-labs-people.txt ").map(_.split(",")).map(p  => Person(p(0), p(1).trim.toInt)).toDF()
```
Replace the hdfs path with the path obtained with Echo command in Step 1.

Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic39.png?raw=true)

```jason
people.registerTempTable("people")
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic40.png?raw=true)

```jason
val teenagers = sqlContext.sql("SELECT name, age FROM people WHERE age >= 13 AND age <= 19")
```

Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic41.png?raw=true)

```jason
teenagers.map(t => "Name: " + t(0)).collect().foreach(println)
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic42.png?raw=true)
	
## LESSONS LEARNT :

1. How to use Apache Spark-shell to interact with Spark cluster. 

## NEXT?

1. How to use Hive command to interact with Hive cluster
