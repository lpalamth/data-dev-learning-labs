### HOW TO USE APACHE SPARK-SHELL TO INTERACT WITH SPARK CLUSTER###

###### Step 1:
From Hadoop Terminal, use echo command to find the path as shown below:
```jason
echo $HDFS
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/HadoopBasic29.png?raw=true)

Note: The path obtained needs to be used in commands shown below to replace {$HDFS}.


###### Step 2:
Spark shell interactive environment needs to be launched from terminal.Please follow the steps given below. User could launch the Spark shell interactive environment either in local mode or in cluster mode but not in both of them.

To launch in Local Mode, please follow the command given below:

```jason
spark-shell
```

