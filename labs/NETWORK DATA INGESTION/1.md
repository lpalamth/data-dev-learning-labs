# <center>NETWORK DATA INGESTION</center>

<b>Stream Processing Platform Used</b>: Apache Kafka

<b>Executed on</b>: Hadoop Big Data Platform


## OVERVIEW

This learning lab can be used as a guide to get a high level understanding on the process of ingesting network data in to Hadoop environment. We will be using DevNet Data Learning Platform referred as "DLP" during the course. In this lab, the network stream data is already pre-created. From DLP platform, the user can access it directly. A data collection server, as shown in the diagram below, is collecting data in real time from the local network. The data collected by the Server is working with a Client residing in DLP to transfer the network data collected through Kafka. Using Kafka socket code, we are making a connection to the client that captures the network data and sends it to a Kafka topic. From this topic, data will be moved to HDFS by a Consumer program. The diagram shows how exactly network data flows from a local network through Kafka in HDFS and gets transformed.

Please refer the example shown below to get a high level understanding :

![alt tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/network-data-transformation/assets/images/flow1.png?raw=true)


## PRE-REQUISITES

1.	Install Chrome Browser.

2.	Obtain access to the Data Learning Platform by creating an account at https://devnetsandbox.cisco.com/RM/Diagram/Index/d8b9476d-cb6f-4b44-a236-b8ebdb3d3ef9?diagramType=Topology (Detailed instructions given below)

3. Basic Knowledge of data storage on Hadoop.

4. Basic knowledge of Apache Kafka.


## LEARNING OBJECTIVES

1. To get familiarized with the DLP (Data Learning Platform).

2. To get familiarized with the ways to get network data from HDFS. 

3. To get familiarized with the ways to ingest network streaming data.

4. To get familiarized with the method of visualizing network data from DLP's platform.


## TERMINOLOGIES USED


### WHAT IS NETWORK DATA? - AN INTRODUCTION

The Computer network is a telecommunication process which allows computers or devices to exchange data between each other using data pipeline and those devices that are controlled by wired or wireless medium. Those devices are kept alive by exchanging data between each other in a continuous way. 

These network data provide the inside details about communication performance between of two devices that are communicating. We can extract lots of valuable information from those data set if we can capture those data in real time. 

## APACHE KAFKA? - AN INTRODUCTION

Kafka is a distributed streaming platform that is designed to be fast, scalable, and durable. It has 3 key capabilities:

1.	It lets you publish and subscribe to streams of records. In this respect it is similar to a message queue or enterprise messaging system.
2.	It lets you store streams of records in a fault-tolerant way.
3.	It lets you process streams of records as they occur.

It is used for two broad classes of application:

1.	Building real-time streaming data pipelines that reliably get data between systems or applications
2.	Building real-time streaming applications that transform or react to the streams of data

For more details, please refer:
https://kafka.apache.org/


### DLP - AN INTRODUCTION ###

The DevNet Data Learning Platform (DLP) is an integrated data platform from CISCO that includes an easy-to-use UI, Docker-    based infrastructure, best-in-class open-source big-data components, and Cisco’s APIs and tools for data developers and data  scientists who want to develop, validate and provision their solutions before deploying or to explore, analyze, and    visualize their data. The DLP environment comes with an inbuilt cloud based IDE (Integrated Development Environment) built    on Hadoop.

For more details, please refer:
https://developer.cisco.com/site/dlp/docs/overview/

## PROCESS OVERVIEW 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Process8.jpeg?raw=true)

Please follow the steps given below to launch the workspace and execute the lab.

### <b>Step 1 : Login to DLP</b>

Access the link - https://developer.cisco.com/site/dlp/ and click on button Request Access. Please refer the screen shown below:</br>. 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess1.jpeg?raw=true)

On click of Request access, you will be navigated to the following page:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess2.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess2.jpeg" width="400" height="300" />

<b>Existing User?</b>

Click on DevNet logo and provide the credentials in the login page. Please refer the screen below:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess7.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess7.jpeg" width="400" height="300" />

On click of DevNet Logo:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess3.jpeg?raw=true)

<b>New User?</b>

Click on “Register Account” button and create a new login profile. Please refer the screen below:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess8.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess8.jpeg" width="400" height="300" />

On click of "Register Account":

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess5.jpeg?raw=true)


<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess6.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess6.jpeg" width="300" height="400" />

On successful registration, navigate to DLP login page and login with the credentials created:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess3.jpeg?raw=true)


### <b>Step 2 : DLP Dashboard Page</b>

On login, you will be directed to the DevNet DLP (Data Learning Platform)dashboard page as shown in the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess4.jpeg?raw=true)

### <b>Step 3 : Select Learning lab and Start</b>

From Learning Labs pane, select the learning lab "Network Data Ingestion" and click on "Start" button as shown in screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion1.png?raw=true)


### <b>Step 4: Workspace Page</b>

On click of Start button, user will be navigated to a workspace page where all the components - IDE, Tools and Microservices required to execute the program are available. Please refer the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion2.png?raw=true)

### <b>Step 5 : Start Tasks in workspace</b>

Points to Note:

* Start the tasks in "Data Source" and "Transform" columns. Once started, the colour of the icons change to green. Please refer screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion5.png?raw=true)

* If the task is in stopped status then click on it to start again. Please refer screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion3.png?raw=true)


Data source section allows to create network real-time data stream. Kafka's producer will push the Network traffic generated data to Kafka cluster and Consumer can consume that data and save that in to HDFS real-time.The transform section allows to save the real-time data to HDFS. From HDFS, we can visualise the data using visualization tool like Tableau. 

The transformed output data is read from HDFS and shown to the user. The generated output file is shown in section - "Data Source - file".</br>

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion6.png?raw=true)

Click on the button with an eye symbol to view the network data as shown in screenshot below.

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/importNetworkData15.PNG?raw=true)

PS: The window needs to be refreshed if the output file is not seen.
</br>


### <b>Step 6 : Stop Tasks in workspace</b>

After viewing the network data, stop the tasks by clicking on <b>Stop</b> button in "Data Source" and "Transform" columns. 
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion7.png?raw=true)

## LESSONS LEARNT:

1. How to ingest network streaming data.

2. How to visualize network data from HDFS via DLP's platform.


# <center>Congratulations! You have successfully completed the Learning Lab!

