# <center>INGESTING NETWORK DATA</center>

<b>Stream Processing Platform Used</b>: Apache Kafka

<b>Executed on</b>: Hadoop Big Data Platform


## OVERVIEW

This learning lab can be used as a guide to get a high level understanding on the process of ingesting network data in to Hadoop environment. We will be using DevNet Data Learning Platform referred as "DLP" during the course. In this lab, the network stream data is already pre-created. From DLP platform, the user can access it directly. A data collection server, as shown in the diagram below, is collecting data in real time from the local network. The data collected by the Server is working with a Client residing in DLP to transfer the network data collected through Kafka. Using Kafka socket code, we are making a connection to the client that captures the network data and sends it to a Kafka topic. From this topic, data will be moved to HDFS by a Consumer program. The diagram shows how exactly network data flows from a local network through Kafka in HDFS and gets transformed.

Please refer the example shown below to get a high level understanding :

![alt tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/network-data-transformation/assets/images/flow1.png?raw=true)


## PRE-REQUISITES

1.	Install Chrome Browser.

2.	Obtain access to the Data Learning Platform by creating an account at https://devnetsandbox.cisco.com/RM/Diagram/Index/d8b9476d-cb6f-4b44-a236-b8ebdb3d3ef9?diagramType=Topology (Detailed instructions given below)

3. Basic Knowledge of data storage on Hadoop.

4. Basic knowledge of Apache Kafka.


## LEARNING OBJECTIVES

1. To get familiarized with the DLP (Data Learning Platform).

2. To get familiarized with the ways to get network data from HDFS. 

3. To get familiarized with the ways to ingest network streaming data.

4. To get familiarized with the process of configuring Kafka and network traffic simulator.

5. To get familiarized with the method of visualizing network data from DLP's platform.


## TERMINOLOGIES USED


### WHAT IS NETWORK DATA? - AN INTRODUCTION

The Computer network is a telecommunication process which allows computers or devices to exchange data between each other using data pipeline and those devices that are controlled by wired or wireless medium. Those devices are kept alive by exchanging data between each other in a continuous way. 

These network data provide the inside details about communication performance between of two devices that are communicating. We can extract lots of valuable information from those data set if we can capture those data in real time. 

## APACHE KAFKA? - AN INTRODUCTION

Kafka is a distributed streaming platform that is designed to be fast, scalable, and durable. It has 3 key capabilities:

1.	It lets you publish and subscribe to streams of records. In this respect it is similar to a message queue or enterprise messaging system.
2.	It lets you store streams of records in a fault-tolerant way.
3.	It lets you process streams of records as they occur.

It is used for two broad classes of application:

1.	Building real-time streaming data pipelines that reliably get data between systems or applications
2.	Building real-time streaming applications that transform or react to the streams of data

For more details, please refer:
https://kafka.apache.org/


### DLP - AN INTRODUCTION ###

The DevNet Data Learning Platform (DLP) is an integrated data platform from CISCO that includes an easy-to-use UI, Docker-    based infrastructure, best-in-class open-source big-data components, and Cisco’s APIs and tools for data developers and data  scientists who want to develop, validate and provision their solutions before deploying or to explore, analyze, and    visualize their data. The DLP environment comes with an inbuilt cloud based IDE (Integrated Development Environment) built    on Hadoop.

For more details, please refer:
https://developer.cisco.com/site/dlp/docs/overview/

## PROCESS OVERVIEW 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Process8.jpeg?raw=true)

Please follow the steps given below to launch the workspace and execute the lab.

###### Step 1: 

Login to DLP (Data Learning Platform)- https://devnetsandbox.cisco.com/RM/Diagram/Index/d8b9476d-cb6f-4b44-a236-b8ebdb3d3ef9?diagramType=Topology by giving the login credentials if the account is already created, else, click on “Register now” button and create a new login profile. The screen shown on click of url is as follows:
If login credentials exist, login by providing the user id and password:
  
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Login Page_1.jpeg?raw=true)

If accessing for the first time, please register and create a new profile:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Register.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Register.jpeg" width="400" height="300" />


###### Step 2: 

After logging in, user will be directed to the sandbox UI as shown in the screen below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Sandbox Lab.jpeg?raw=true)

###### Step 3:

User needs to click on the Reserve button shown in sandbox page as shown in the screenshot below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Sandbox Lab.jpeg?raw=true)

###### Step 4:

On click of reserve button, a pop up window is shown with the details as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Reserve_page1.jpeg?raw=true)

###### Step 5:

On click of Reserve button on the pop up window, user would receive an email on registered email ID with the login credentials. The email format would be as shown below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/email_2.jpeg?raw=true)

###### Step 6:

User needs to click on the link given in the email. On click of the link, the following page would be shown to the user.

Supply the credentials recieved with the email and click on “Login”.

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/dlp login page.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/dlp login page.jpeg" width="400" height="300" />

###### Step 7:

On login, user would be directed to the DevNet DLP (Data Learning Platform)dashboard page as shown in the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/DevNetLanding.jpeg?raw=true)

###### Step 8:

From Learning Labs pane, select the learning lab "Network Data Ingestion" and click on "Start" button as shown in screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion1.png?raw=true)


###### Step 9:

On click of Start button, user will be navigated to a workspace page where all the components - IDE, Tools and Microservices required to execute the program are available. Please refer the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion2.png?raw=true)

###### Step 10:

Points to Note:

* Start the tasks in "Data Source" and "Transform" columns. Once started, the colour of the icons change to green. Please refer screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion5.png?raw=true)

* If the task is in stopped status then click on it to start again. Please refer screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion3.png?raw=true)


Data source section allows to create network real-time data stream. Kafka's producer will push the Network traffic generated data to Kafka cluster and Consumer can consume that data and save that in to HDFS real-time.The transform section allows to save the real-time data to HDFS. From HDFS, we can visualise the data using visualization tool like Tableau. 

The transformed output data is read from HDFS and shown to the user. The generated output file is shown in section - "Data Source - file".</br>

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion6.png?raw=true)

Click on the button with an eye symbol to view the network data as shown in screenshot below.

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/importNetworkData15.PNG?raw=true)

PS: The window needs to be refreshed if the output file is not seen.
</br>


###### Step 10:

After viewing the network data, stop the tasks by clicking on <b>Stop</b> button in "Data Source" and "Transform" columns. 
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/NETWORK%20DATA%20INGESTION/assets/images/NetworkDataIngestion7.png?raw=true)

## LESSONS LEARNT:

1. How to ingest network streaming data.

2. How to configure Kafka and network traffic simulator.

3. How to visualize network data from HDFS via DLP's platform.


# <center>Congratulations! You have successfully completed the Learning Lab!

