# <center>Develop a Stream Handler for Cisco CSA</center>


<b>Introduction about Cisco® Connected Streaming Analytics (CSA) </b><br>

Cisco® Connected Streaming Analytics (CSA) is an analytics platform that delivers predictive, actionable insights from high-velocity streams of live data.

* Streaming query processing supports active, continuous monitoring of live data. This provides instantaneous, real-time analysis and action, as well as efficient use of compute resources. 
* CSA’s framework and interfaces are ideal for use case development across a wide variety of business and network management functions and industries. 
* CSA provides real-time insights with big data views to support actionable events and dynamic dashboards to help you get more value out of your data. 

<font color='red'>Request access to the Data Learning Platform by sending a message to:</font> [datalearningplatform@cisco.com](mailto:datalearningplatform@cisco.com)


## Lab Overview

In this Learning Lab, you will learn how to develop CSA custom handlers for using CSA in our DLP platform.<br>
Our platform has Kafka messaging framework working from backend. This utility will take the IP, Port and the Topic details of Kafka messaging system. The application will listen to a local socket continuously and will push the stream from this socket to the Kafka. Our sample Java code for handling the log data stream. This java file need to mention in the XML configuration file.

![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/csa.jpg?raw=true)

## Lab Objective

* Building custom handler for CSA in DLP and analyze the data at real time. 

## Prerequisites

* knowledge on Java 1.6 or above.
* knowledge on SQL query.
* knowledge using GitHub.
* Basic knowledge on XML.
* Chrome Browser.


### Now we are going to demo for a web server log Analysis step by step.

In this Web Server Log Analysis demo, we are going to use a Log Simulator, CSA Engine and the customized handler. First we need to create the environment. For creating environment, we need to start the Log simulator and CSA engine. This can be done through the configuration file which will build the handler.


<b>Step 1:</b> Explore Data Learning Platform(DLP)

<font color='red'>Request access to the Data Learning Platform by sending a message to:</font> [datalearningplatform@cisco.com](mailto:datalearningplatform@cisco.com)

<b>Step 2:</b> From DLP platform, open <b>App Stack Hub</b> option and click on <b>Create Stack</b> button from top-right corner.

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/AppStackStoreSelection.PNG?raw=true)

<b>Step 3:</b>Clicking on <b>Create Stack</b> button, below screen will open. Fillup all the details as given below.

<b>Stack Name : </b>Always should be Unique.

<b>Rack host  : </b>Select the rack from which rack it will be run.

Now click on the submit button to create the stack.

![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/step7.jpg?raw=true)


<b>Step 4:</b> After creating the stack drag and drop the Log simulator and TruCQ source library.<br> 
![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/stackConfig.PNG?raw=true)


<b>N.B</b> If you can't find <b>LogSimulator</b>, <b>TrueCQ</b> under <b>DataSource List</b> it means that the services are not available. In this case, please click on the <b>Micro Service Hub</b> and then click on <b>DevNet Docker</b> tab. Select truecq and select "Add to My Service List". Please follow the below screen shot.
</br><b>Micrservice Hub->DevNet Docker</b> </br>
![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/SelectmicroService.png?raw=true) </br>
<b>Follow same process for selection of Logsimulator</b>


<b>Step 5:</b> For Configuration of the Microservices,Please select a single Microservice and click on the <b>Config</b> button.

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/CSA_5.png?raw=true) 


Now configure the Kafka topic in log simulator and Trucq for CSA.<br>

For Log Simulator we need to configure Kafka Ip ,Port and Topic the configuration will be the following.

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/CSA_2.png?raw=true)

For Trucq the configuration will be the following.

<b>Memory(MB) :</b> 1024     // We suggest to give minimum 512 MB menory size for CSA Engine.

<b>Countainer Port :</b> 5432  TCP   // Please add a container port to access the CSA Engine by SQL Commands.

</br>
![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/CSA_3.png?raw=true)

<b>Step 6:</b> Now we need to start both of this micro service..<br> Click on the <b>Stack Library</b>
![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/StartService.PNG?raw=true)

Click on the Green arrow button for starting both the micro services.

![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/runMicroservices.png?raw=true)

Running state of two micro services:
![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/truecqAndlogsimuPort.png?raw=true)

<b>Step 7:</b> After running Trucq, we will get IP and port. The First IP and port for SQL query to CSA Engine those will vary in every startup.<br>
For example:<br>

```
     10.10.10.92:8652	    // 8652 is the SQL query Listener Port
```

<b>Step 8:</b> <b>Select CSA customize handler <b>"wksp-csa-handler"</b> and click on <b>"Launch"</b>
![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/CSAWorkSpaceSelection.PNG?raw=true)

On clicking on <b>Launch</b> button, the IDE will be launched based on workspace.
![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/csa-IDE.PNG?raw=true)

<b>Step 9:</b> All the basic configurations are written in “include-handler.xml” file. Find this file in below location: <b>CsaCustomHandler-->build-->tmp-->include-handler.xml.</b> Double click on it and open it in right panel.<br>

![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/csa-includehandler.PNG?raw=true)

<b>Step 10:</b> In the “include-handler.xml” file set the kafka Topic and Kafka Zookeeper IP and Port and change the name of the custom class which we are going to develop. Here handler java class name is ETLHandler.java.

```
	<topic>CiscoDDP</topic>     // Change the Kafka Topic here.
	<arguments>
 		<arg name="zookeeper.connect">172.16.11.10:2181/kafka</arg>  //Configure IP & Port
	</arguments>
	<custom class="custom.handlers.ETLHandler” </custom>        
	//Set the Handler Java Class which we are going to code next step
```

<b>Step 11 :</b> Sample Java class for CSA handler is placed in below path. Here we named it as ETLHandler.<br>
<b>CsaCustomHandler --> customizations --> src --> ETLHandler.java </b>

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/ETLHandlerClass.PNG?raw=true)

<b><u>Sample Coding Exercise</u></b><br>

```
package custom.handlers;

import org.apache.commons.configuration.SubnodeConfiguration;
import com.cisco.pa.handlers.model.DataRecord;
import com.truviso.system.handlers.AbstractEntryHanlder;
import com.truviso.system.handlers.HandlerException;

public class ETLHandler extends AbstractEntryHanlder<DataRecord, DataRecord> {
	String string;
	public ETLHandler(SubnodeConfiguration c) {
		super(c);
	}
	@Override
	public void init() throws HandlerException {
		super.init();
        try {
        	string = config.getString("string", "POST");
               } catch (IllegalArgumentException e) {}
	}
	@Override
	public void handle(DataRecord record) throws HandlerException {

		try {
			if (null != record) {
				if (record.toString().contains(string))
					resultListener.handle(record);
			}

		      } catch (Exception ex) {throw new HandlerException(ex);}}}
```



<b>Step 12:</b> Above Truecq IP and Port number details are required to set the handler. We need to update the configuration file.<br> Open the IDE and double click on the below file

<b>CsaCustomHandler-->customizations-->instances-->local-runtime.properties</b><br>

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/aaaaa.png?raw=true)

<b>Step 13:</b>In this step we need to stop the handler first. In the top of the IDE we can select stop from the combo. <br>
![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/step13.jpg?raw=true)

<b>Step 14:</b>In this step we need to build our handler. In the top of the IDE we can select build from the combo.<br>
![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/step14.jpg?raw=true)

<b>Step 15:</b>In this step we need to Start our handler to select Run. In the top of the IDE we can select run from the combo.<br>
![Figure](https://raw.githubusercontent.com/prakdutt/data-dev-learning-labs/master/labs/develop-stream-handler-cisco-csa/assets/images/step15.jpg)


<b>Step 16:</b>Now we can start Zeppelin for visualization. In the Data Repository we will get the  </>Drill button.<br>
![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/ZepplineSelection.PNG?raw=true)

<b>Step 17:</b>: Now we need to configure Zeppelin. When the Trucq micro service is running, we need to collect the IP and Port from the End Point for SQL query listener.<br>
![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/CSA_4.png?raw=true)

Now we need to create a new Zeppelin Note for CSA and edit the PSQL configuration with below mentioned parameters.<br>

```
postgresql.driver.name    :  org.postgresql.Driver
postgresql.max.result     :  1000
postgresql.password	  : 
postgresql.url		  :  jdbc:postgresql://10.10.10.92:8652/cqdb
postgresql.user	          :  trucq

```
Click <b>Interpreter</b> from Zepplin and reach <b>psql</b> section. After clicking on <b>Edit</b> button, edit the respective details as described above and click on <b>Save</b> button. 
![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/ZapplineConfigurationRestart.png?raw=true) </br>

After clicking on <b>Save</b> button, click the <b>OK</b> button for final updation. </br>
![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/ZapplineConfigurationUpdate.PNG?raw=true)

After setting the above value, click on the <b>Restart</b> button.
![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/ZapplineConfigurationRe.PNG?raw=true) </br>

<b>Step 18:</b> After restarting the configuration we can execute the SQL queries to the CSA engine and plot the graph according to data stream. 
Till now, we have configured the process of reading log data from multiple Web servers located in different location. In below, we will do the query to view the log data using sql query on web server's log data which are stored in postgresql database(configured in above steps). User can learn the process of log status from log data using sql query and display the data in different format(table/graph) as per their choice. 

```
%psql
select * from apachelog.sapachelog_archive order by access_time DESC limit 300
```
This query will show the output as below. It is showing the web server's log server data from CSA engine. These log data are stored in the postgresql database which is mentioned in above step. 
![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/ZepplinePreview.png?raw=true)

On clicking on the Settings icon(marked in above image), we can drag and drop the fields as mentioned in below screen and display the output as graph format. User can change the graph based on their choice. 
![Figure](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/develop-stream-handler-cisco-csa/assets/images/zeppelinSqlQurery.png?raw=true)


### Things to Try

Developers can build their own application for the Run Time Visualization, CSA engine or Trucq support Restful web services and also support SQL queries to fetch the data from the Engine.

### Reference:
1.	 [http://www.cisco.com/c/dam/en/us/products/collateral/analytics-automation-software/streaming-analytics/connected-streaming-analytics-aag.pdf](http://www.cisco.com/c/dam/en/us/products/collateral/analytics-automation-software/streaming-analytics/connected-streaming-analytics-aag.pdf)

2.	[http://www.cisco.com/c/dam/en/us/products/collateral/analytics-automation-software/streaming-analytics/connected-streaming-analytics.pdf](http://www.cisco.com/c/dam/en/us/products/collateral/analytics-automation-software/streaming-analytics/connected-streaming-analytics.pdf)
 


## <center>Thank You</center>
