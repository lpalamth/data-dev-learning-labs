# **BASIC DATA VISUALIZATION USING APACHE ZEPPELIN**

Programming Language Used : Python

Executed on : Hadoop Big Data Platform

Visualization Tool Used : Apache Zeppelin

## OVERVIEW

This learning lab can be used as a guide to get a high level understanding of using Python with Zeppelin. It describes how to use Python functions and write interactive Python code from Zeppelin. It also gives a description to plot data using matplotlib library and the  usage of numpy library for creating cosine wave. We will be using DevNet Data Learning Platform referred as "DLP" during the course. 

## PRE-REQUISITES

1.	Install Chrome Browser.

2.	Obtain access to the Data Learning Platform by creating an account at https://devnetsandbox.cisco.com/RM/Diagram/Index/d8b9476d-cb6f-4b44-a236-b8ebdb3d3ef9?diagramType=Topology (Detailed instructions given below)

3.	Basic understanding of Apache Hadoop and Big Data.

4. Basic knowledge of SQL (Structured Query Language).

5. Basic knowledge of Python.



## LEARNING OBJECTIVES

1. To get familiarized with the DLP (Data Learning Platform).

2. To get familiarized with writing and executing python code in Zeppelin. 

3. To get familiarized with the usage of numpy library for creating a cosine wave.

4. To get familiarized with the usage of matplotlib library to plot data.

</br>

## TERMINOLOGIES USED


### APACHE ZEPPELIN - AN INTRODUCTION

Zeppelin is a web-based notebook that enables interactive data analytics. You can make beautiful data-driven, interactive and collaborative documents with SQL, Scala and more. </br>

Zeppelin enables data engineers, data analysts and data scientists to be more productive by developing, organising, executing, and sharing data code and visualising results without referring to the command line or knowing the cluster details. It brings data exploration, visualization, sharing and collaboration features to Spark. It supports Python and also a growing list of programming languages such as Scala, Hive, SparkSQL, shell and markdown. The various languages are supported via Zeppelin language interpreters. Zeppelin’s notebooks provides interactive snippet-at-time experience to data scientist.


###### Key Features:

1. Web based notebook style editor.

2. Built-in Apache Spark support.

###### Use Cases for Zeppelin :

1. Data Exploration and discovery

2. Data Visualization - Tables,graphs and charts

3. Interactive snippet-at-a-time experience

4. Collaboration and publishing

For more details, please refer : https://zeppelin.apache.org/


### APACHE SPARK - AN INTRODUCTION 

Apache Spark is an open source cluster computing framework. Spark is advertised as “lightning fast cluster computing”. It has a thriving open-source community and is the most active Apache project at the moment. Spark provides an interface for programming entire clusters with implicit data parallelism and fault-tolerance. Apache Spark provides programmers with an application programming interface centered on a data structure called the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way. 

It was developed in response to limitations in the MapReduce cluster computing paradigm, which forces a particular linear dataflow structure on distributed programs. MapReduce programs read input data from disk, map a function across the data, reduce the results of the map, and store reduction results on disk. Spark provides a faster and more general data processing platform.

###### Key Features

1. Currently provides APIs in Scala, Java, and Python, with support for other languages (such as R) on the way
2. Integrates well with the Hadoop ecosystem and data sources (HDFS, Amazon S3, Hive, HBase, Cassandra, etc.)
3. Can run on clusters managed by Hadoop YARN or Apache Mesos, and can also run standalone

###### How to Use Apache Spark? 

###### Example : Using spark to detect an earthquake by analyzing the twitter stream

1. Using Spark streaming, filter tweets that seem relevant like “earthquake” or “shaking”. 

2. Run semantic analysis on the tweets to determine if they appear to be referencing a current earthquake occurrence. Tweets like ”Earthquake!” or ”Now it is shaking”, for example, would be considered positive matches, whereas tweets like “Attending an Earthquake Conference” or ”The earthquake yesterday was scary” would not. 

3. Using the streaming technique we could detects the  positive tweets in a defined time window and thereby can be used to send alert messages.

For more details, please refer:
http://spark.apache.org/
https://en.wikipedia.org/wiki/Apache_Spark


### DLP - AN INTRODUCTION ###

The DevNet Data Learning Platform (DLP) is an integrated data platform from CISCO that includes an easy-to-use UI, Docker-    based infrastructure, best-in-class open-source big-data components, and Cisco’s APIs and tools for data developers and data  scientists who want to develop, validate and provision their solutions before deploying or to explore, analyze, and    visualize their data. The DLP environment comes with an inbuilt cloud based IDE (Integrated Development Environment) built    on Hadoop.

For more details, please refer:
https://developer.cisco.com/site/dlp/docs/overview/

## PROCESS OVERVIEW 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/process.jpeg?raw=true)

Please follow the steps given below to launch the workspace and execute the word count program.

###### Step 1: 

Login to DLP (Data Learning Platform)- https://devnetsandbox.cisco.com/RM/Diagram/Index/d8b9476d-cb6f-4b44-a236-b8ebdb3d3ef9?diagramType=Topology by giving the login credentials if the account is already created, else, click on “Register now” button and create a new login profile. The screen shown on click of url is as follows:
If login credentials exist, login by providing the user id and password:
  
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Login Page_1.jpeg?raw=true)

If accessing for the first time, please register and create a new profile:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Register.jpeg?raw=true)


###### Step 2: 

After logging in, user will be directed to the sandbox UI as shown in the screen below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Sandbox Lab.jpeg?raw=true)

###### Step 3:

User needs to click on the Reserve button shown in sandbox page as shown in the screenshot below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Sandbox Lab.jpeg?raw=true)

###### Step 4:

On click of reserve button, a pop up window is shown with the details as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Reserve_page1.jpeg?raw=true)

###### Step 5:

On click of Reserve button on the pop up window, user would receive an email on registered email ID with the login credentials. The email format would be as shown below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/email_2.jpeg?raw=true)

###### Step 6:

User needs to click on the link given in the email. On click of the link, the following page would be shown to the user.

Supply the credentials recieved with the email and click on “Login”.

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/dlp login page.jpeg?raw=true)


###### Step 7:

On login, user would be directed to the DevNet DLP (Data Learning Platform) as shown in the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/data-explore-using-zeppelin/assets/Trial1.jpeg?raw=true)

###### Step 8:

Select the file <b>(bank-full.csv)</b> and click on the <b>Drill</b> button shown on top-right corner of the screen as shown in screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/data-explore-using-zeppelin/assets/Zeppelin2.jpeg?raw=true)


###### Step 8:

User would be presented with two options - Zeppelin and Jupyter. Select Zeppelin.

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/data-explore-using-zeppelin/assets/selectZappline.PNG?raw=true)

(The pop-up may be blocked in browser configuration. Click on the red pop up blocker icon and select <b>Always allow pop-up from http://xxx.xxx.xxx.xxx </b> and click on <b>Done</b> button.) </br> 

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/data-explore-using-zeppelin/assets/popUpBlockerAllowed.PNG?raw=true)

###### Step 9:
On enabling the pop-up, Zeppelin would open in a new window taking the user to Zeppelin home page. Create your own notebook by clicking on <b>Create new note</b> as shown in screenshot below.

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/data-explore-using-zeppelin/assets/welcome-to-zeppelin.PNG?raw=true)





2. Create a notebook with a new name in the pop-up dialogue box. 
Input a valid name based on your choice and click on the <b>Creat Note</b> button.
![alt-img](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/data-visualization-with-zeppelin/assets/images/image5CreateNewNotbook.png?raw=true)

3. A newly created notebook will open.
![alt-img](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/data-visualization-with-zeppelin/assets/images/image6ZeppelineNotebookEditor.PNG?raw=true)

</br>
<b>*Upto this steps, we have created our environment on Zeppelin. Now we will try to use some Python functions and view the output directly from Zeppelin. Python is already installed in out DLP platform. In our example code, we will try to view the Cosine signal data.*</b>

## Step 3: Create cosine signal data. 
**Preparing Python code for data generation** </br>
Input the code as given below. After entering code in Zeppelin notebook UI, click on the <b>Execute</b> button to execute the code. </br>
The details about the code is in below: </br>
i) Import numpy library from Zeppelin UI. </br>
*Numpy is the fundamental package for scientific computing with python. It contains very powerful mathematical functions. In this learning lab, we will use the function that is defined in Numpy to create cosine signal data. Before we use these functions, we should import Numpy library.* </br>
ii) Define a numpy array which should be eventually distributed along (-Pi, Pi). The syntax of numpy.linspace is as below.
numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)
</br>
Reference URL is : http://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html </br>

Return evenly spaced numbers over a specified interval.
Returns num evenly spaced samples, calculated over the interval [start, stop]. </br>
iii) Define an array y=cos(x). </br>
iv) Printing all the <b>cosine</b> values from array. </br>

```json
%python
import numpy as np                                                     #Import numpy library
x = np.linspace( -np.pi, np.pi , 1000)                                 #Define a numpy array which should be eventually distributed along (-Pi, Pi).
y = np.cos(x)                                                          #Define an array y = cos(x)
print x,y                                                              #Print the cosine signal data
```
![alt-img](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/data-visualization-with-zeppelin/assets/images/pythonCodeLoadData1.png?raw=true)


</br>
After executing the above code, user can view the cosine signal data in Zeppelin.
![alt-img](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/data-visualization-with-zeppelin/assets/images/pythonCodeLoadDataOutput1.PNG?raw=true)

## Step 4: Plotting the cosine signal.
In the previous step, we have created the cosine signal data. Now we need to plot those cosine signal data. <b>Matplotlib</b> is a python 2D plotting library that produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. In this learning lab, we will use the function of Matplotlib library to plot the figure. </br>
Below is the python code which will help to draw the Cosine curve by plotting the cosine data. </br>
Details about the code for drawing the Cosine curve is in below:</br>
i)   Import Matplotlib, StringIO library in Zeppelin. </br>
ii)  Plot the cosine signal in memory. </br>
iii) Create StringIO object for reading string buffer data from memory. </br>
iv)  Create an image with cosine data reading from memory in svg format. </br>
v)   Get the starting memory address of the image which has created in step iv. </br>
vi)  Show cosine signal curve in Zeppelin UI. </br>
```json
%python
import matplotlib.pyplot as plt                                        #Import matplotlib library
import StringIO

plt.plot(x,y)                                                          #Plot the cosine signal in memory

img = StringIO.StringIO()                                              #Create StringIO object which named img
plt.savefig(img, format='svg')                                         #Save the figure in svg format
img.seek(0)                                                            #Get the memory of the figure
print "%html <div style='width:300pt'>" + img.buf + "</div>"           #Show the cosine signal curve
```
Copy the above code in Zeppelin notebook UI and execute the code by clicking on the <b>Execute</b> button. This code will generate and display the Cosine curve on Zeppelin.
![alt-img](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/data-visualization-with-zeppelin/assets/images/visualizationScreen2.PNG?raw=true)





   
