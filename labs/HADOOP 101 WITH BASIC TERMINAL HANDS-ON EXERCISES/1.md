# <center>HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES</center>

<b>Executed on</b> : Hadoop Terminal

## OVERVIEW

This learning lab can be used as a guide to get a high level understanding of Apache Hadoop. The prime focus would be to,

1. Get a basic understanding of Hadoop infrastructure.

2. Learn how to execute HDFS command. 

3. Learn how to use Apache Spark-shell to interact with Spark cluster.

4. Learn how to use Hive command to interact with Hive cluster

We will be using DevNet Data Learning Platform referred as "DLP" during the course. 

## PRE-REQUISITES

1.	Install Chrome Browser.

2.	Obtain access to the Data Learning Platform by creating an account at https://devnetsandbox.cisco.com/RM/Diagram/Index/d8b9476d-cb6f-4b44-a236-b8ebdb3d3ef9?diagramType=Topology (Detailed instructions given below)

3. User should have a basic exposure to Core Java, database concepts and any of the Linux operating system flavors.


## LEARNING OBJECTIVES

1. To get familiarized with the DLP (Data Learning Platform)

2. To get familiarized with Apache Hadoop.

3. To get familiarized with the terminal usage for executing HDFS commands.

## TERMINOLOGIES USED

### HADOOP - AN INTRODUCTION ###

What is Hadoop?

Hadoop is an open-source framework that allows to store and process big data in a distributed environment across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Hadoop splits files into large blocks and distributes them across nodes in a cluster. All the modules in Hadoop are designed with a fundamental assumption that hardware failures are common and should be automatically handled by the framework.

There are two fundamental things about Hadoop :

1. File Storage (known as Hadoop Distributed File System (HDFS)
2. Data Processing (known as MapReduce)

<b>Hadoop Evolution Overview</b>

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/Hadoop.jpeg?raw=true)

<b>Hadoop Architecture</b>

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/Hadoop Architecture.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HOW TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/Hadoop Architecture.jpeg" width="600" height="300" />

Hadoop framework includes following four modules:

1. <b>Hadoop Common:</b> These are Java libraries and utilities required by other Hadoop modules. These libraries provides filesystem and OS level abstractions and contains the necessary Java files and scripts required to start Hadoop.

2. <b>Hadoop YARN:</b> A framework for job scheduling and cluster resource management.

3. <b>Hadoop Distributed File System (HDFS™):</b> A distributed file system that provides high-throughput access to application data.
4. <b>Hadoop MapReduce:</b> A YARN-based system for parallel processing of large data sets.

For more details, please refer:

https://en.wikipedia.org/wiki/Apache_Hadoop

http://hadoop.apache.org/


### DLP - AN INTRODUCTION ###

The DevNet Data Learning Platform (DLP) is a Big-Data learning platform connected with an easy to learn UI to help you break into the world of Big-Data development.  Backed with Docker, best-in-class open source Big-Data tools and Cisco API’s, Big-Data Scientists and Developers can leverage DLP to easily build solutions, visualize data and turn POC’s for production applications. The DLP environment comes with an inbuilt cloud based IDE (Integrated Development Environment) built on Hadoop.

For more details, please refer:
https://developer.cisco.com/site/dlp/docs/overview/


## PROCESS OVERVIEW 

In this learning lab, we will focus on three different exercises which are as follows:

1.	How to execute HDFS command. 

2.	How to use Apache Spark-shell to interact with Spark cluster.

3.	How to use Hive command to interact with Hive cluster


### HOW TO EXECUTE BASIC HDFS COMMAND ###

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Process10.jpeg?raw=true)

Please follow the steps given below to launch the workspace and execute the program.

### <b>Step 1 : Login to DLP</b>

Access the link - https://developer.cisco.com/site/dlp/ and click on button Request Access. Please refer the screen shown below:</br>. 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess1.jpeg?raw=true)

On click of Request access, you will be navigated to the following page:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess2.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess2.jpeg" width="400" height="300" />

<b>Existing User?</b>

Click on DevNet logo and provide the credentials in the login page. Please refer the screen below:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess7.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess7.jpeg" width="400" height="300" />

On click of DevNet Logo:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess3.jpeg?raw=true)

<b>New User?</b>

Click on “Register Account” button and create a new login profile. Please refer the screen below:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess8.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess8.jpeg" width="400" height="300" />

On click of "Register Account":

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess5.jpeg?raw=true)


<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess6.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess6.jpeg" width="300" height="400" />

On successful registration, navigate to DLP login page and login with the credentials created:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess3.jpeg?raw=true)

### <b>Step 2 : DLP Dashboard Page</b>

On login, you will be directed to the DevNet DLP (Data Learning Platform)dashboard page as shown in the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess4.jpeg?raw=true)

### <b>Step 3 : Select Learning Lab and Start</b>

From Learning Labs pane, select the learning lab "Hadoop 101 with basic terminal hands-on exercises" and click on "Start" button as shown in screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic1.png?raw=true)

### <b>Step 4 : Workspace Page</b>

On click of Start button, you will be navigated to a workspace page where all the components - IDE, Tools and Microservices required to execute the program are made available. Please refer the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic2.png?raw=true)

### <b>Step 5 : Tasks in Workspace</b>

Points to Note:

The following files will be used for executing this learning lab and are made available in workspace (DataSource - File):

1. hadoop-learning-labs-demo.txt
2. hadoop-learning-labs-people.json
3. hadoop-learning-labs-people.txt
4. hive_students.csv

* The task in Tools and Microservices - Others should be in running status and the colour of the icon should be Green for launch button to be enabled. Please refer screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic4.png?raw=true)

* If the task is in killed status then click on it to start again. Please refer screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic3.png?raw=true)

### <b>Step 6 : Launch Hadoop Terminal</b>

On click of launch button, you will be navigated to hadoop terminal which would open in a separate tab as shown in screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic5.png?raw=true)

</br>
*********************** Provide login id and password on the terminal prompt as shown in screenshot below: (Login ID : root / Password : cisco)************
</br>

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic10.png?raw=true)

### <b>Step 7 : Execute Basic Commands</b>

Execute some of the basic commands in hadoop terminal. 

Please find each command snippet with the output. Copy paste each of the commands given below to the terminal and view the output obtained.

<b>Create a directory in HDFS:</b>

```jason
hdfs dfs -mkdir ${HDFS}learning-labs/
```

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic11.png?raw=true)

To view output:

```jason
hdfs dfs -ls ${HDFS}
```

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic12.png?raw=true)

Please Note: 
HDFS – Environment Parameter 
Learning-labs – directory name

<b>File upload to HDFS from local desktop:</b>

* Create a file in the local system with the content as hello, hadoop-learning-labs. Please follow the command mentioned below to do so:

```jason
echo “hello, hadoop-learning-labs” >> hadoop-learning-labs.txt
```
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic13.png?raw=true)

* Upload file via -put or -copyFromLocal command from local file to HDFS.

```jason
hdfs dfs –put hadoop-learning-labs.txt ${HDFS}learning-labs/
```
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic15.png?raw=true)

* View the uploaded file as follows:

```jason
hdfs dfs –ls ${HDFS}learning-labs/
```
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic17.png?raw=true)


### <b>Step 8 : File download from HDFS to local desktop</b>


P.S: if hadoop-learning-labs.txt file exists in local directory then it needs to be deleted first. 

* Remove file - "hadoop-learning-labs.txt" from local directory if it exists.

```jason
rm hadoop-learning-labs.txt
```
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic18.png?raw=true)

* Get the file from HDFS to local directory using -get command

```jason
hdfs dfs –get ${HDFS}learning-labs/hadoop-learning-labs.txt
```
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic19.png?raw=true)

To view output:

```jason
ls –lh hadoop-learning-labs.txt 
```
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic20.png?raw=true)


### <b>Step 9 : List Files or View File Content in HDFS directory.</b>


* List the files in HDFS directory:

```jason
hdfs dfs –ls ${HDFS}learning-labs/
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic23.png?raw=true)

2. View the contents of the file "hadoop-learning-labs.txt" present in HDFS directory:

```jason
hdfs dfs –cat ${HDFS}learning-labs/hadoop-learning-labs.txt
```
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic22.png?raw=true)

### <b>Step 10 : Copy, move or remove files in HDFS</b>

1. Create a new directory:

```jason
hdfs dfs –mkdir ${HDFS}learning-labs-move/
```
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic46.png?raw=true)

2. Copy or move files from one directory to another:

```jason
hdfs dfs –cp ${HDFS}learning-labs/hadoop-learning-labs.txt  ${HDFS} learning-labs-move/
```

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic47.png?raw=true)

To view output:

```jason
hdfs dfs -ls ${HDFS}learning-labs-move/
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic49.png?raw=true)

### <b>Step 11 : Delete a file from HDFS</b>

```jason
hdfs dfs –rm ${HDFS}learning-labs-move/hadoop-learning-labs.txt
```

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic50.png?raw=true)
         
To view output:

```jason
hdfs dfs -ls ${HDFS}learning-labs-move
```
Output of the command is as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic51.png?raw=true)


### <b>Step 12 : Explore other commands in Hadoop</b>

To explore more commands , use help command as shown below:

```jason
hdfs dfs –help
```
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/HadoopBasic52.png?raw=true)

## LESSONS LEARNT :

1. How to execute basic HDFS commands in Hadoop Terminal. 

## NEXT?

1. How to use Apache Spark-shell to interact with Spark cluster.
