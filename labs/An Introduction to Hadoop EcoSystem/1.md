# <center>AN INTRODUCTION TO APACHE HADOOP ECOSYSTEM</center>

Executed on : Hadoop Terminal

## OVERVIEW

This learning lab can be used as a guide to get a high level understanding of Apache Hadoop. The prime focus would be to

1. Get a basic understanding of Hadoop infrastructure.

2. Learn how to execute HDFS command. 

3.	Learn how to use Apache Spark-shell to interact with Spark cluster.

4.	Learn how to use Hive command to interact with Hive cluster

 We will be using DevNet Data Learning Platform referred as "DLP" during the course. 

## PRE-REQUISITES

1.	Install Chrome Browser.

2.	Obtain access to the Data Learning Platform by creating an account at https://devnetsandbox.cisco.com/RM/Diagram/Index/d8b9476d-cb6f-4b44-a236-b8ebdb3d3ef9?diagramType=Topology (Detailed instructions given below)

3. User should have a basic exposure to Core Java, database concepts and any of the Linux operating system flavors.


## LEARNING OBJECTIVES

1. To get familiarized with the DLP (Data Learning Platform)

2. To get familiarized with Apache Hadoop.

3. To get familiarized with the terminal usage for executing HDFS commands.

## TERMINOLOGIES USED

### HADOOP - AN INTRODUCTION ###

What is Hadoop?

Hadoop is an open-source framework that allows to store and process big data in a distributed environment across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Hadoop splits files into large blocks and distributes them across nodes in a cluster. All the modules in Hadoop are designed with a fundamental assumption that hardware failures are common and should be automatically handled by the framework.

There are two fundamental things about Hadoop :

1. File Storage (known as Hadoop Distributed File System (HDFS)
2. Data Processing (known as MapReduce)

Hadoop Evolution Overview

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/An Introduction to Hadoop EcoSystem/assets/images/Hadoop.png?raw=true)

Hadoop Architecture

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/An Introduction to Hadoop EcoSystem/assets/images/Hadoop Architecture.png?raw=true)

Hadoop framework includes following four modules:

1. <b>Hadoop Common:</b> These are Java libraries and utilities required by other Hadoop modules. These libraries provides filesystem and OS level abstractions and contains the necessary Java files and scripts required to start Hadoop.

2. <b>Hadoop YARN:</b> This is a framework for job scheduling and cluster resource management.

3. <b>Hadoop Distributed File System (HDFS™):</b> A distributed file system that provides high-throughput access to application data.
4. <b>Hadoop MapReduce:</b> This is YARN-based system for parallel processing of large data sets.


For more details, please refer:

https://en.wikipedia.org/wiki/Apache_Hadoop

http://hadoop.apache.org/


### DLP - AN INTRODUCTION ###

The DevNet Data Learning Platform (DLP) is a Big-Data learning platform connected with an easy to learn UI to help you break into the world of Big-Data development.  Backed with Docker, best-in-class open source Big-Data tools and Cisco API’s, Big-Data Scientists and Developers can leverage DLP to easily build solutions, visualize data and turn POC’s for production applications. The DLP environment comes with an inbuilt cloud based IDE (Integrated Development Environment) built on Hadoop.

For more details, please refer:
https://developer.cisco.com/site/dlp/docs/overview/


## PROCESS OVERVIEW 

In this learning lab, we will focus on three different exercises which are as follows:

1.	How to execute HDFS command. 

2.	How to use Apache Spark-shell to interact with Spark cluster.

3.	How to use Hive command to interact with Hive cluster


### HOW TO EXECUTE HDFS COMMAND ###

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Process1.jpeg?raw=true)

Please follow the steps given below to launch the workspace and execute the program.

###### Step 1: 

Login to DLP (Data Learning Platform)- https://devnetsandbox.cisco.com/RM/Diagram/Index/d8b9476d-cb6f-4b44-a236-b8ebdb3d3ef9?diagramType=Topology </br>. 

Give the login credentials if the account is already created, else, click on “Register now” button and create a new login profile. The screen shown on click of url is as follows:
If login credentials exist, login by providing the user id and password:
  
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Login Page_1.jpeg?raw=true)

If accessing for the first time, please register and create a new profile:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Register.jpeg?raw=true)


###### Step 2: 

After logging in, user will be directed to the sandbox UI as shown in the screen below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Sandbox Lab.jpeg?raw=true)

###### Step 3:

User needs to click on the Reserve button shown in sandbox page as shown in the screenshot below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Sandbox Lab.jpeg?raw=true)

###### Step 4:

On click of reserve button, a pop up window is shown with the details as shown below:
![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/Reserve_page1.jpeg?raw=true)

###### Step 5:

On click of Reserve button on the pop up window, user would receive an email on registered email ID with the login credentials. The email format would be as shown below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/email_2.jpeg?raw=true)

###### Step 6:

User needs to click on the link given in the email. On click of the link, the following page would be shown to the user.

Supply the credentials recieved with the email and click on “Login”.

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/dlp login page.jpeg?raw=true)

###### Step 7:

On login, user would be directed to the DevNet DLP (Data Learning Platform)dashboard page as shown in the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/DevNetLanding.jpeg?raw=true)

###### Step 8:

From Learning Labs pane, select the learning lab "Word Count Using Scala Programming with Apache Spark" and click on "Start" button as shown in screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/DevNetLanding1.jpeg?raw=true)

###### Step 9:

On click of Start button, user will be navigated to a workspace page where all the components - IDE, Tools and Microservices required to execute the program are available. Please refer the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/DevNetWrkSpcTask2.jpeg?raw=true)



## LESSONS LEARNT :

1. A 

## <center>Congratulations! You have successfully completed the Learning Lab!
