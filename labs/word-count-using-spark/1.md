# <center>WORDCOUNT PROGRAM</center>

Programming Language Used : [Scala](http://www.scala-lang.org/what-is-scala.html)
Framework Used : [Apache Spark](https://en.wikipedia.org/wiki/Apache_Spark)
Executed on : [Hadoop](https://en.wikipedia.org/wiki/Apache_Hadoop)

## OVERVIEW

This learning lab can be used as an example to learn scala programming language.The DevNet Data Learning Platform (DLP) is an integrated data platform that includes an easy-to-use UI, Docker-based infrastructure, best-in-class open-source big-data components, and Ciscoâ€™s APIs and tools for data developers and data scientists who want to develop, validate and provision their solutions before deploying or to explore, analyze, and visualize their data. The DLP environment comes with an inbuilt cloud based IDE (Integrated Development Environment) built on Hadoop.

WordCount program is used as an example to demonstrate the use of Scala programming language on Hadoop.


After completing this lab exercise, a user can try their own spark program using different data file from Hadoop environment.

<font color='red'>Request access to the Data Learning Platform by sending a message to:</font> [datalearningplatform@cisco.com](mailto:datalearningplatform@cisco.com)

## OBJECTIVES

To get familiarized with the DLP (Data Learning Platform)
To get familiarized with the RDD operations on data using spark.
To learn to write programs using scala programming language.
To learn to print data to a new file.

## Prerequisites

* Basic knowledge of Hadoop to store the data.
* Basic knowledge of how spark works.
* Chrome Browser.

## Step 1: Explore Data Learning Platform(DLP)
DLP platform is pre-populated with workspace for executing different programming language. For using the Spark programming language, user needs to select the below workspace.

1)	After logging on DLP, click on <b>Development Hub</b> on the left column.<br>
2)	Select the pre-defined work space named as <b>wksp-wordcount</b>.<br>
3)	Click on the <b>Launch</b> button to open IDE workspace.<br>

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/SelectWorkSpace.PNG?raw=true)

## Step 2: Explore IDE Workspace
For writing any programming language, DLP platform is pre-loaded with an IDE. User can write Spark programming language in this IDE. </br>
Files are listed in Left Panel of this IDE. Double-clicking on any file, right panel will be populated with the content of that specified file. User can directly edit the content from there. </br>
*Below files are required for this learning lab. Except for these files, other files should be used for another learning lab which are not related to this learning lab. </br>
WordCount.scala, WordCountRun.sh, wordcountinputfiles2.txt.* </br>

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/WordCountScalafile.PNG?raw=true)


``` json
//Import libraries which are needed to run the program. 
import org.apache.spark.{SparkContext, SparkConf}
object WordCount
{
  def main(args: Array[String]) {
    val inputFile = args(0)
    val outputFile = args(1)
    val conf = new SparkConf().setAppName("wordCount")
    // Create a Scala Spark Context.
    val sc = new SparkContext(conf)
    // Load our input data.
    val input = sc.textFile(inputFile)
    // Split up into words.
    val words = input.flatMap(line => line.split(" "))
    // Transform into word and count.
    val counts = words.map(word => (word, 1)).reduceByKey{_ + _}
    // Save the word count back out to a text file, causing evaluation.
    counts.saveAsTextFile(outputFile)
  }
}
```
N.B: Use WordCount.scala to view the above code. 
In the above, Scala code using Spark is using to read the input file (passed as a parameter), generate the Spark context, Read the input file and split words using a single space and increment the counter of each occurance of word and write the output in console.

**Edit input file name with a sentence.** </br>
Double click on wordcountinputfiles2.txt from the left panel. This file name may differ for differenet user. Edit the file by adding some content there.
![alt-img](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/EditInputFile.png?raw=true)

## Step 3: Build and Execute Spark Program from DLP's IDE 

In this step, User will learn the process of packaging the program from DLP's Cloud IDE. User can use the sample word count program to package and build. This process will work on DLP's Hadoop environment.
1) Double click on WordCound.scala file again. Change <b>package</b> as described in the below image and click on the <b>run</b> blue button. This process will build and package the program.
![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/buildWordCount.PNG?raw=true)

2) You can find the below screen if build process finished successfully.
![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/buildSuccessWordCount.PNG?raw=true)

3) If the build process finished successfully, then select <b>run</b> as described in the below image and click on <b>blue run</b> button again. 
![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/runWordCount.PNG?raw=true)

4) The Successful execution of run process will show the output as below. (There should NOT be any Exception message in the exception window if run process finished successfully.)
![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/successfulBuildProcess.png?raw=true)

## Step 4: Displaying output from DLP's IDE. 
Below steps are describing the process of generating the displaying the output. 

1) After completing above steps, open the <b>view.sh</b> by double clicking on it. Select <b>view</b> and click on the <b>blue run</b> button to view the output.

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/viewOutput.png?raw=true)

This will show the number of occurance of each word in the output window. <b>view.sh</b> file is used to pickup the file from Hadoop environment and show the output in IDE's output window. 


Here Input file has the text: <b>Hello spark I love Cisco Company. Hello all. We are practising Word Count Program using Scala and Spark.</b>
Output content is as below:
```json
(are,1)
(Program,1)
(Hello,2)
(love,1)
(Word,1)
(practising,1)
(using,1)
(We,1)
(Scala,1)
(spark,1)
(Count,1)
(I,1)
(Company.,1)
(Spark.,1)
(Cisco,1)
(and,1)
(all.,1)
```

Things to Try:

* Try with numeric data type
* Try with case sensitive data as well.

Completing this coding exercise, we have learned how to count the number of words in an input file using Spark Batch Processing. <br>

## REFERENCES

http://www.scala-lang.org/what-is-scala.html
https://en.wikipedia.org/wiki/Apache_Spark



There are few more examples and exercises are available in the below-mentioned link. This is for your reference.
[http://spark.apache.org/docs/latest/programming-guide.html](http://spark.apache.org/docs/latest/programming-guide.html).
