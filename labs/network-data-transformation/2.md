###### Step 10: 

On click of launch, user will be navigated to a pre-configured IDE (Integrated Development Environment). Select the file “TransformData.java” from left pane on IDE work space. Double click on the file and it will open up in the right panel. Please refer the screenshot below:

![alt tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/network-data-transformation/assets/images/ide1.PNG?raw=true)

###### Step 11: 

From the top pane of IDE, select CMD as “Package” and click on blue icon (![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/icon.jpeg?raw=true)) as shown in the screenshot below:

![alt tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/network-data-transformation/assets/images/ide2.PNG?raw=true)

Note : This will help to build and package the scala program.

###### Step 12: 

Check the console for a successful completion message:

###### Step 13: 

We need to perform below settings before we run the program and generate the result. Below steps describe the process of generating and saving the output from the above program in the Hadoop platform. 
a)	Select the <b>run.sh</b> file from the left panel and double click on it. The contents of the file will open in the right panel.

There are three parameters mentioned in this script file. Change the values as described below and Select the CMD as “run” and click on blue icon(![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/word-count-using-spark/assets/images/icon.jpeg?raw=true)) as shown in the screenshot below:

* USER: your current login user name </br>

<b>N.B</b> Enter your loggedin userid. If you have logged in as user_1 then enter user_1 as USER. </br>

* INPUT: The file name in “Data Repository” section that you want to transform. </br>

<b>N.B:</b> Sample preloaded network data file(network_origin.csv) is already saved in HDFS environment. User can use this file as an example.</br>

* OUTPUT: The output file name that the code will generate.  </br>

<b>N.B</b> Provide a output file name. For example, <b>network_transform_result.csv</b> is used as a output file name here. Output of the program would be saved in this file and the file would be saved in Hadoop environment directly. <b>Change this file name based on your choice. </b>

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/network-data-transformation/assets/images/runScriptFile.PNG?raw=true)


###### Step 14: 

Check the console for a successful completion message:


###### Step 15: 

After executing the above script, DLP's Cloud IDE will generate the output file and save directly in the Hadoop platform. We can view the output using visualisation tool - Tableau.

###### Step 16: 

Navigate to DLP and from Data Repository tab, select the output file name that was given in run.sh file (Refer Step 13 for more details).

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/vizualize-csv-tableau/assets/images/select_data_in_repo.png?raw=true)

###### Step 17: 
Click on the view button indicated with an eye symbol (as shown in the screenshot above), output file would look as shown below:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/network-data-transformation/assets/images/rawDataDisplay.PNG?raw=true)

###### Step 18: 

Click on the <b>Visualize</b> button shown on top-right corner of the screen as shown in screenshot below:

The pop-up may be blocked in browser configuration. Please refer the screenshot below:

![alt-img](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/vizualize-csv-tableau/assets/images/DataVisualizationTablueBrowserBlockingMsg1.PNG?raw=true)

Click on the pop up blocker icon and select <b>Always allow pop-up from http://xxx.xxx.xxx.xxx </b> and click on <b>Done</b> button.) </br> 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/vizualize-csv-tableau/assets/images/unblock_popups_screen.png?raw=true)

###### Step 19:
On enabling the pop-up, select the output file and click on <b>Visualize</b> button. Tableau workbook would open in a seperate tab and user can view the data dimensions and measures as shown in screenshot below:

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/vizualize-csv-tableau/assets/images/tableau_wkbk.png?raw=true)

###### Step 20:

User can now explore the data with drag and drop operations and create reports.

The user can select the required field(s) and view the data in desired format. For example, select ip_src(IP address of source devices) and ip_dest(IP address of destination devices) fields from Dimensions column and place it as shown in the below screen. 
It will generate the output as dot marks that shows there is traffic flow between two devices. IP addresses of devices which are communicating with each other are marked on X-axis and Y-Axis respectively. Please refer the screenshot below:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/network-data-transformation/assets/images/tableauUIOnNetworkData.PNG?raw=true)
</br>
The User can select any other fields based on their own choice to display the output. 

Sample Code: Transform a network data file and store transformed file to HDFS.

Below is the sample code used for getting the CSV file containing network data from HDFS environment, perform the transformation and store the transformed data back to HDFS. 

```java
//Import the below libraries which are used to run the code.
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.FileUtil;
import org.apache.hadoop.fs.Path;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.function.FlatMapFunction;

import java.util.Arrays;
//Class: TransformData. A class that transform the network data
public class TransformData {

    public static void main(String [] args) throws Exception {


  //three parameters here
        String filePath= args[0];
        String outputPath= args[1];
        String distFilePath= args[2];

        final String seperatorField = ",";

        //System.out.println("master address:"+master);
        System.out.println("input file path:"+filePath);
// here we are giving application name as “File transform”
        SparkConf conf = new SparkConf().setAppName("File transform");
        JavaSparkContext sc = new JavaSparkContext(conf);

        JavaRDD<String> textFile = sc.textFile(filePath);

        JavaRDD<String> cols = textFile.flatMap(new FlatMapFunction<String, String>() {
            public Iterable<String> call(String s) {
                String [] splits = s.split(seperatorField) ;

                String extractedCols = "";

                for(int i= 1 ;i<= 6 ;i ++ ){
                    extractedCols += splits[i ] + seperatorField ;
                }

                if(extractedCols.endsWith(seperatorField)){
                    extractedCols = extractedCols.substring(0,extractedCols.length() - 1)  ;
                }

                return Arrays.asList(extractedCols);
            }
        });


       cols.coalesce(1).saveAsTextFile(outputPath);

       boolean bool = getMergeInHdfs(outputPath,distFilePath);
        System.out.println("merge success:"+bool);



    }

    public static boolean getMergeInHdfs(String src, String dest) throws IllegalArgumentException, Exception {

        Configuration config = new Configuration();
        FileSystem fs = FileSystem.get(config);
        Path srcPath = new Path(src);
        Path dstPath = new Path(dest);

        // Check if the path already exists
        if (!(fs.exists(srcPath))) {
            System.out.println("Path " + src + " does not exists!");
            return false;
        }

        if ((fs.exists(dstPath))) {
            System.out.println("File Path " + dest + " exists!");
            return false;
        }

        return FileUtil.copyMerge(fs, srcPath, fs, dstPath, true, config, null);
    }
}
```
## LESSONS LEARNT

1. How to get network data from HDFS.

2. How to transform network data by creating transform function using IDE.

3. How to visualize data using Tableau.


# <center>Congratulations! You have successfully completed the Learning Lab!



