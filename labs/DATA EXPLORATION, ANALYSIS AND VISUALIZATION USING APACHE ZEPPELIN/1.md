
# <center>DATA EXPLORATION, ANALYSIS AND VISUALIZATION USING APACHE ZEPPELIN</center>

Processing Engine Used : Apache Spark

Language Used : SQL

Executed on : Hadoop Big Data Platform

Visualization tool used : Apache Zeppelin


## OVERVIEW

This learning lab can be used as a guide to get a high level understanding of Apache Spark with Zeppelin. It describes how to interpret a pre-loaded static data, analyze and visualize the data using Zeppelin. The data resides in Hadoop environment and Zeppelin interacts with the data using Spark by forming RDD on the data set. 

We will be using DevNet Data Learning Platform referred as "DLP" during the course. 


## PRE-REQUISITES

1.	Install Chrome Browser.

2.	Obtain access to the Data Learning Platform by creating an account at https://devnetsandbox.cisco.com/RM/Diagram/Index/d8b9476d-cb6f-4b44-a236-b8ebdb3d3ef9?diagramType=Topology(Detailed instructions given below)

3.	Basic understanding of Apache Spark, Apache Hadoop and Big Data.

4. Basic knowledge of SQL (Structured Query Language).

## LEARNING OBJECTIVES

1. To get familiarized with the DLP (Data Learning Platform).

2. To get familiarized with the RDD operations on data using Apache Spark. 

3. To get familiarized with the ways to read and format (CSV) HDFS files by using Apache Spark

3. To get familiarized with data analysis and visualization using Apache Zeppelin.


## TERMINOLOGIES USED


### APACHE ZEPPELIN - AN INTRODUCTION

Zeppelin is a web-based notebook that enables interactive data analytics. You can make beautiful data-driven, interactive and collaborative documents with SQL, Scala and more. </br>

Zeppelin enables data engineers, data analysts and data scientists to be more productive by developing, organising, executing, and sharing data code and visualising results without referring to the command line or knowing the cluster details. It brings data exploration, visualization, sharing and collaboration features to Spark. It supports Python and also a growing list of programming languages such as Scala, Hive, SparkSQL, shell and markdown. The various languages are supported via Zeppelin language interpreters. Zeppelin’s notebooks provides interactive snippet-at-time experience to data scientist.


###### Key Features:

1. Web based notebook style editor.

2. Built-in Apache Spark support.

###### Use Cases for Zeppelin :

1. Data Exploration and discovery

2. Data Visualization - Tables,graphs and charts

3. Interactive snippet-at-a-time experience

4. Collaboration and publishing

For more details, please refer : https://zeppelin.apache.org/


### APACHE SPARK - AN INTRODUCTION 

Apache Spark is an open source cluster computing framework. Spark is advertised as “lightning fast cluster computing”. It has a thriving open-source community and is the most active Apache project at the moment. Spark provides an interface for programming entire clusters with implicit data parallelism and fault-tolerance. Apache Spark provides programmers with an application programming interface centered on a data structure called the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way. 

It was developed in response to limitations in the MapReduce cluster computing paradigm, which forces a particular linear dataflow structure on distributed programs. MapReduce programs read input data from disk, map a function across the data, reduce the results of the map, and store reduction results on disk. Spark provides a faster and more general data processing platform.

###### Key Features

1. Currently provides APIs in Scala, Java, and Python, with support for other languages (such as R) on the way
2. Integrates well with the Hadoop ecosystem and data sources (HDFS, Amazon S3, Hive, HBase, Cassandra, etc.)
3. Can run on clusters managed by Hadoop YARN or Apache Mesos, and can also run standalone

###### How to Use Apache Spark? 

###### Example : Using spark to detect an earthquake by analyzing the twitter stream

1. Using Spark streaming, filter tweets that seem relevant like “earthquake” or “shaking”. 

2. Run semantic analysis on the tweets to determine if they appear to be referencing a current earthquake occurrence. Tweets like ”Earthquake!” or ”Now it is shaking”, for example, would be considered positive matches, whereas tweets like “Attending an Earthquake Conference” or ”The earthquake yesterday was scary” would not. 

3. Using the streaming technique we could detects the  positive tweets in a defined time window and thereby can be used to send alert messages.

For more details, please refer:
http://spark.apache.org/
https://en.wikipedia.org/wiki/Apache_Spark


### DLP - AN INTRODUCTION ###

The DevNet Data Learning Platform (DLP) is an integrated data platform from CISCO that includes an easy-to-use UI, Docker-    based infrastructure, best-in-class open-source big-data components, and Cisco’s APIs and tools for data developers and data  scientists who want to develop, validate and provision their solutions before deploying or to explore, analyze, and    visualize their data. The DLP environment comes with an inbuilt cloud based IDE (Integrated Development Environment) built    on Hadoop.

For more details, please refer:
https://developer.cisco.com/site/dlp/docs/overview/

## PROCESS OVERVIEW 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Process2.jpeg?raw=true)

Please follow the steps given below to launch the workspace and execute the word count program.


### <b>Step 1 : Login to DLP</b>

Access the link - https://developer.cisco.com/site/dlp/ and click on button Request Access. Please refer the screen shown below:</br>. 

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess1.jpeg?raw=true)

On click of Request access, you will be navigated to the following page:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess2.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess2.jpeg" width="400" height="300" />

<b>Existing User?</b>

Click on DevNet logo and provide the credentials in the login page. Please refer the screen below:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess7.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess7.jpeg" width="400" height="300" />

On click of DevNet Logo:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess3.jpeg?raw=true)

<b>New User?</b>

Click on “Register Account” button and create a new login profile. Please refer the screen below:

<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess8.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess8.jpeg" width="400" height="300" />

On click of "Register Account":

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess5.jpeg?raw=true)


<img src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess6.jpeg" data-canonical-src="https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess6.jpeg" width="300" height="400" />

On successful registration, navigate to DLP login page and login with the credentials created:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess3.jpeg?raw=true)

### <b>Step 2 : DLP Dashboard Page</b>

On login, you will be directed to the DevNet DLP (Data Learning Platform)dashboard page as shown in the screenshot below:

![alt-tag](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess4.jpeg?raw=true)

### <b>Step 3 : Select Learning Lab and Start</b>

From Learning Labs pane, select the learning lab "Data Exploration, Analysis and Visualization using Apache Zeppelin" and click on "Start" button as shown in screenshot below:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore4.jpeg?raw=true)

### <b>Step 4 : Workspace Page</b>

On click of Start button, user will be navigated to a workspace page where all the components - IDE, Tools and Microservices required to execute the program are available. Please refer the screenshot below:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore9.jpeg?raw=true)

### <b>Step 5 : Tasks in Workspace</b>

Points to Note:

* The task in Cloud IDE should be in running status and the colour of the icon should be Green for launch button to be enabled. Please refer screenshot below:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore1.png?raw=true)

* If the task is in stopped status then click on it to start again. Please refer screenshot below:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore2.png?raw=true)


### <b>Step 6 : Launch Zeppelin</b>

Click on launch button and user will be navigated to Zeppelin home page.

Points to note:

(The pop-up may be blocked in browser configuration. Click on the red pop up blocker icon and select <b>Always allow pop-up from http://xxx.xxx.xxx.xxx </b> and click on <b>Done</b> button.) </br> 

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/popUpBlockerAllowed.PNG?raw=true)

On enabling the pop-up, Zeppelin would open in a new window taking the user to Zeppelin home page as shown in screenshot below.

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore10.jpeg?raw=true)


### <b>Step 7 : Select Zeppelin notebook</b>

* Select pre-created notebook - "zeppelin-learning-labs" from home page as shown in screenshot below:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore11.jpeg?raw=true)

* The Zeppelin interactive,development and visualisation environment is now ready for use. The notebook - "zeppelin-learning-labs" has all the codes required for executing this learning lab. Please refer the screenshot below. Each of the code shown below needs to be executed sequentially.

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore5.jpeg?raw=true)

### <b>Step 8 : Execute Apache Spark Code</b>

We are using code written in Apache Spark to create resilient distributed dataset (RDD) using bank-full.csv file. The file bank-full.csv is already loaded in Hadoop environment.</br>  

The code is as follows:

```jason
val bankText = sc.textFile("hdfs://172.16.1.11:8020/user/U5850a40a98a794401f399c6f/99dd17b9-a13b-4fb0-ba97-c66fc7bd5ac0//bank-full.csv")  

case class Bank(age:Integer, job:String, marital : String, education : String, balance : Integer)

// split each line, filter out header (starts with "age"), and map it into Bank case class

val bank = bankText.map(s=>s.split(";")).filter(s=>s(0)!="\"age\"").map(  
       s=>Bank(s(0).toInt, 
            s(1).replaceAll("\"", ""),  
            s(2).replaceAll("\"", ""),  
            s(3).replaceAll("\"", ""),  
            s(5).replaceAll("\"", "").toInt  
        )  
)
bank.toDF().registerTempTable("bank")
```

Following functions are being done by the Spark Code :

* Header removal using filter function and data transformation from csv format into RDD of Bank objects.

* RDD conversion to DataFrame and temporary table creation with name “bank”.


Execute the code by clicking on the icon highlighted as shown in screenshot below:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore6.jpeg?raw=true)
</br>


On successful execution of code, the screen would be as shown in the screenshot below:

The icon changed to Finished and there would not be any errors shown on the screen.

Below screen shows that the spark RDD is created successfully and creation of a temporary table "bank" is also done:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore7.jpeg?raw=true)

### <b>Step 9 : SQL Query to Retrieve and Visualize data</b>

We have now completed the data loading process. Next, we will use SQL queries in Zeppelin to retrieve and visualize the data loaded. Let's try a few examples to visualize the data in Zeppelin.

<b>Example 1:</b> Age distribution of data that is stored in bank RDD. 
</br>
Execute the below mentioned query from Zeppelin Editor (Refer Example 1):

```sql
%sql 
select age, count(1) from bank where age < 30 group by age order by age
```
![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore12.jpeg?raw=true)

The output is as shown below:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore13.jpeg?raw=true)

Change the graph type to pie chart and view the output as shown below:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore14.jpeg?raw=true)


<b>Example 2:</b> Input run-time data as input box and display output. 

Execute the below mentioned query from Zeppelin Editor (Refer Example 2):

```sql
%sql
select age, count(1) count from bank where age < ${maxAge=30} group by age order by age
```

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore15.jpeg?raw=true)
</br>

Enter value as 28 in the input box, select graph type as pie chart and view the output as shown below.

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore16.jpeg?raw=true)



<b>Example 3:</b> Using dynamic sql query to select data from a drop down list box. 

Execute the below mentioned query from Zeppelin Editor (Refer Example 3):

```sql
%sql
select age, count(1) count from bank where marital = "${marital=single,single|divorced|married}" group by age order by age
```
The output displays the age distribution with marital status and a combo box to select marital status as shown in the screenshot below:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore18.jpeg?raw=true)

Select value as "Married" from the combo box, select graph type as "Graph" and view the output as shown below:

![Figure](https://github.com/lpalamth/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/ZeppelinExplore19.jpeg?raw=true)

## LESSONS LEARNT

1. How to perform RDD operations on data using Apache Spark. 

3. How to read and format (CSV) HDFS files by using Apache Spark

3. How to do data analysis and visualization using Apache Zeppelin.


# <center>Congratulations! You have successfully completed the Learning Lab!

